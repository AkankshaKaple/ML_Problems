{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Chatbot</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "An AI based chatbot where we have to predict the answer of the user's asked question.\n",
    "## Dataset:\n",
    "Here we are using Bridgelabz fellowship program's frequently asked questions as dataset for tr\n",
    "\n",
    "## Solution:\n",
    "Here, we will use Natural Language Processing (NLP) for text processing and for prediction Machine learning Support Vector Machine (SVM) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immersive Experience to be gained ?\n",
    "This notebook is a detailed investigation on AI based chatbot, how it will work, how we will pre-process the chatbot dataset and how we predict the answer from user's asked question.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import all the required libraries \n",
    "\n",
    "* __NLTK__ : The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing for English written in the Python programming language\n",
    "* __Pandas__ : In computer programming, pandas is a software library written for the Python programming language for data manipulation and analysis and storing in a proper way. In particular, it offers data structures and operations for manipulating numerical tables and time series\n",
    "* __Numpy__ : NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "* __Sklearn__ : Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy. The library is built upon the SciPy (Scientific Python) that must be installed before you can use scikit-learn.\n",
    "* __Pickle__ : Python pickle module is used for serializing and de-serializing a Python object structure. Pickling is a way to convert a python object (list, dict, etc.) into a character stream. The idea is that this character stream contains all the information necessary to reconstruct the object in another python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:07:58.550824Z",
     "start_time": "2019-10-16T16:07:51.984487Z"
    }
   },
   "outputs": [],
   "source": [
    "#Loading libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Read all the required data and combine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:02.283402Z",
     "start_time": "2019-10-16T16:08:02.128420Z"
    }
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "try:\n",
    "    faq = pd.read_csv('Data/chatbot_faq.csv')\n",
    "    greeting = pd.read_csv('Data/Greetings.csv')\n",
    "except (FileNotFoundError, IOError):\n",
    "    print(\"Wrong file or file path\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will concat the faq and greeting in one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:02.922666Z",
     "start_time": "2019-10-16T16:08:02.911380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 5)\n",
      "                                       Question        DomainIntent  \\\n",
      "0           How long is the fellowship program?  fellowship program   \n",
      "1        How much does fellowship program cost?  fellowship program   \n",
      "2               What is the fellowship program?  fellowship program   \n",
      "3  Can the fellowship program be done remotely?  fellowship program   \n",
      "4                              How do I get in?  fellowship program   \n",
      "\n",
      "               Intent                                             Answer  \\\n",
      "0            duration      The program is 4 months on a full-time basis.   \n",
      "1      admission_fees   The program is free to the fellows. You do no...   \n",
      "2  fellowship program  Coding jobs with emerging tech product compani...   \n",
      "3         remote work   No! We believe that interaction with the ment...   \n",
      "4               enter   You will require to register for one of our r...   \n",
      "\n",
      "     Class  \n",
      "0  general  \n",
      "1  general  \n",
      "2  general  \n",
      "3  general  \n",
      "4  general  \n"
     ]
    }
   ],
   "source": [
    "print(faq.shape)\n",
    "print(faq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:03.090359Z",
     "start_time": "2019-10-16T16:08:03.079988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 5)\n",
      "    Question        DomainIntent     Intent  Answer      Class\n",
      "0      Hello  fellowship program  greetings      Hi  greetings\n",
      "1         Hi  fellowship program  greetings   Hello  greetings\n",
      "2        Hii  fellowship program  greetings   Hello  greetings\n",
      "3        Hey  fellowship program  greetings      Hi  greetings\n",
      "4  Hey There  fellowship program  greetings     Hey  greetings\n"
     ]
    }
   ],
   "source": [
    "print(greeting.shape)\n",
    "print(greeting.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:03.270157Z",
     "start_time": "2019-10-16T16:08:03.265233Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.concat([faq, greeting], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we read the data, we can look at the data using:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:03.640319Z",
     "start_time": "2019-10-16T16:08:03.634735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 51 rows and 5 columns\n",
      "[['What is the working hours of the training program?' ' fellowship'\n",
      "  ' time'\n",
      "  ' From morning 8.30 AM to 7.30 PM the fellowship engineers are expected to code. In the beginning it is data structures later it is live sample app and lastly it is to develop App solving the real-world problem statement.']\n",
      " ['Hello' 'fellowship program' 'greetings' 'Hi']\n",
      " ['Hi' 'fellowship program' 'greetings' 'Hello']]\n"
     ]
    }
   ],
   "source": [
    "print ('The dataset has {0} rows and {1} columns'.format(data.shape[0],data.shape[1]))\n",
    "print(data.iloc[29:32,:-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:03.863850Z",
     "start_time": "2019-10-16T16:08:03.838584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Question        DomainIntent  \\\n",
      "21      Do I have weekends off in fellowship program?  fellowship program   \n",
      "36                              Hey, How is it going?  fellowship program   \n",
      "1              How much does fellowship program cost?  fellowship program   \n",
      "46                                       Good Morning  fellowship program   \n",
      "30                                              Hello  fellowship program   \n",
      "49                                           Good Day  fellowship program   \n",
      "17  What percentage of the fellowship is developin...  fellowship program   \n",
      "42                              Hi, nice to meet you.  fellowship program   \n",
      "40                                  Nice to meet you.  fellowship program   \n",
      "12       What happens to fellows after they graduate?  fellowship program   \n",
      "19  What tools will fellowship engineer get a chan...  fellowship program   \n",
      "20  how much time will take to complete fellowship...  fellowship program   \n",
      "34                                          Hey There  fellowship program   \n",
      "6   Do fellowship program offer any stipend or liv...  fellowship program   \n",
      "13  How much package I get after the fellowship pr...  fellowship program   \n",
      "33                                                Hey  fellowship program   \n",
      "50                                          Whats up?  fellowship program   \n",
      "24    what is the duration of the fellowship program?  fellowship program   \n",
      "16                What does the day-to-day look like?  fellowship program   \n",
      "25         What tools will I get a chance to work on?  fellowship program   \n",
      "27                       Where training will be held?  fellowship program   \n",
      "26  What tools will fellowship engineer get a chan...  fellowship program   \n",
      "14                   What will be my starting salary?  fellowship program   \n",
      "44                                            See you  fellowship program   \n",
      "2                     What is the fellowship program?  fellowship program   \n",
      "43                                                Bye  fellowship program   \n",
      "38                                            Whatsup  fellowship program   \n",
      "37                                              Howdy  fellowship program   \n",
      "23                What does the day-to-day look like?  fellowship program   \n",
      "45                                               Tata  fellowship program   \n",
      "10      What can I expect in the technical interview?  fellowship program   \n",
      "47                                     Good Afternoon  fellowship program   \n",
      "31                                                 Hi  fellowship program   \n",
      "5       How do I register for the fellowship program?  fellowship program   \n",
      "3        Can the fellowship program be done remotely?  fellowship program   \n",
      "39                                 How are you doing?  fellowship program   \n",
      "32                                                Hii  fellowship program   \n",
      "8   What do I need to know to be able to get throu...  fellowship program   \n",
      "35                               Hi, How is it going?  fellowship program   \n",
      "15  What type of projects will the fellowship engi...  fellowship program   \n",
      "48                                       Good Evening  fellowship program   \n",
      "4                                    How do I get in?  fellowship program   \n",
      "18           What tools will I get a chance to learn?  fellowship program   \n",
      "11  What can fellowship engineer expect in the tec...  fellowship program   \n",
      "7   Do fellowship program offer any package or liv...  fellowship program   \n",
      "0                 How long is the fellowship program?  fellowship program   \n",
      "29  What is the working hours of the training prog...          fellowship   \n",
      "28        How do I get admission in training program?          fellowship   \n",
      "22           Do I need to pay for fellowship program?  fellowship program   \n",
      "41                                     How do you do?  fellowship program   \n",
      "9   What is the minimum qualification for the fell...  fellowship program   \n",
      "\n",
      "                   Intent                                             Answer  \\\n",
      "21    weekly_off  weekend            Yes you will get every week sunday off.   \n",
      "36              greetings                                               Fine   \n",
      "1          admission_fees   The program is free to the fellows. You do no...   \n",
      "46              greetings                                       Good Morning   \n",
      "30              greetings                                                 Hi   \n",
      "49              greetings                                           Good Day   \n",
      "17           applications   100% of fellowship engineers will be involved...   \n",
      "42              greetings                                Thank you. You too.   \n",
      "40              greetings                                          Thank you   \n",
      "12                    job   We have placed more than 500 engineers till d...   \n",
      "19           technologies   Essentially the Tech Stack we work on are And...   \n",
      "20               duration      The program is 4 months on a full-time basis.   \n",
      "34              greetings                                                Hey   \n",
      "6   stipend accomodations   We are currently helping deserving students w...   \n",
      "13                package   Our fellows get salaries benchmarked with the...   \n",
      "33              greetings                                                 Hi   \n",
      "50              greetings                                           Not much   \n",
      "24               duration      The program is 4 months on a full-time basis.   \n",
      "16             daily work   From morning 8.30 AM to 7.30 PM the fellowshi...   \n",
      "25           technologies   Essentially the Tech Stack we work on are And...   \n",
      "27               location                                            Mumbai.   \n",
      "26           technologies   Essentially the Tech Stack we work on are And...   \n",
      "14                 salary   Our fellows get salaries benchmark with the b...   \n",
      "44              greetings                                                Bye   \n",
      "2      fellowship program  Coding jobs with emerging tech product compani...   \n",
      "43              greetings                                            see you   \n",
      "38              greetings                                       Nothing much   \n",
      "37              greetings                                                Hey   \n",
      "23                 timing   From morning 8.30 AM to 7.30 PM the fellowshi...   \n",
      "45              greetings                                                Bye   \n",
      "10              interview   The first interview depending on your skills ...   \n",
      "47              greetings                                     Good Afternoon   \n",
      "31              greetings                                              Hello   \n",
      "5          register apply   You can register here: http://codingtest.brid...   \n",
      "3             remote work   No! We believe that interaction with the ment...   \n",
      "39              greetings                                               Good   \n",
      "32              greetings                                              Hello   \n",
      "8                  coding   Try our sample MCQ questions from the Coding ...   \n",
      "35              greetings                                               Good   \n",
      "15                project   The fellowship engineers work on the actual r...   \n",
      "48              greetings                                       Good Evening   \n",
      "4                   enter   You will require to register for one of our r...   \n",
      "18           technologies   Essentially the Tech Stack we work on are And...   \n",
      "11              interview   The first interview depending on your skills ...   \n",
      "7                 package   We are currently helping deserving students w...   \n",
      "0                duration      The program is 4 months on a full-time basis.   \n",
      "29                   time   From morning 8.30 AM to 7.30 PM the fellowshi...   \n",
      "28                 action   You can register here: http://codingtest.brid...   \n",
      "22         admission_fees   The program is free to the fellows. You do no...   \n",
      "41              greetings                                     I'm doing well   \n",
      "9           qualification   All the candidates need to be Engineers or MC...   \n",
      "\n",
      "        Class  \n",
      "21    general  \n",
      "36  greetings  \n",
      "1     general  \n",
      "46  greetings  \n",
      "30  greetings  \n",
      "49  greetings  \n",
      "17    general  \n",
      "42  greetings  \n",
      "40  greetings  \n",
      "12    general  \n",
      "19    general  \n",
      "20    general  \n",
      "34  greetings  \n",
      "6     general  \n",
      "13    general  \n",
      "33  greetings  \n",
      "50  greetings  \n",
      "24    general  \n",
      "16    general  \n",
      "25    general  \n",
      "27    general  \n",
      "26    general  \n",
      "14    general  \n",
      "44  greetings  \n",
      "2     general  \n",
      "43  greetings  \n",
      "38  greetings  \n",
      "37  greetings  \n",
      "23    general  \n",
      "45  greetings  \n",
      "10    general  \n",
      "47  greetings  \n",
      "31  greetings  \n",
      "5     general  \n",
      "3     general  \n",
      "39  greetings  \n",
      "32  greetings  \n",
      "8     general  \n",
      "35  greetings  \n",
      "15    general  \n",
      "48  greetings  \n",
      "4     general  \n",
      "18    general  \n",
      "11    general  \n",
      "7     general  \n",
      "0     general  \n",
      "29    general  \n",
      "28    general  \n",
      "22    general  \n",
      "41  greetings  \n",
      "9     general  \n"
     ]
    }
   ],
   "source": [
    "#shuffle the data\n",
    "data = data.sample(frac=1)\n",
    "print(data.sample(frac=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:04.731017Z",
     "start_time": "2019-10-16T16:08:04.003339Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('01_shuffle_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stage, we'll deal with outlier values, encode variables and take every possible initiative which can remove inconsistencies from the data set. Let's remove that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* First we'll tokenzie each word from the dataset.\n",
    "* After we tokenize, we will start cleaning up the tokens by Lemmatizing. Lemmatizing is the process of converting a word into its root form. \n",
    "- __Tokenizing__ : This breaks up the strings into a list of words or pieces based on a specified pattern using Regular Expressions aka RegEx. \n",
    "- eg : white brown fox = ‘white’, ‘brown’,’fox’\n",
    "- __Lemmatizing__ : Lemmatizing is the process of converting a word into its root form.\n",
    "- e.g., \"Playing\", \"Played\" = \"play\".\n",
    "\n",
    "In cleanup() function, we are first tokenizing the sentence (seperating each word in sentence) and then steeming (converting a word into its root form) and at the end combine all the words to form a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After removing unwanted data let's do some steps to make our data understandable for our program. That's why we do preprocessing.\n",
    "- Here we are dealing with text data, we can understant it but our machines can't. So we need to convert the data from text to numeric form.  \n",
    "- Vectorization :The process of converting NLP text into numbers is called vectorization in ML.\n",
    "- TF-IDF : TF-IDF stands for term frequency-inverse document frequency. It tell how important a word is in a sentence. The importance of a word depends on the number of times it occured in a sentence. To understand it, let's see each term:\n",
    "- __Term Frequency(TF)__ : How frequently a word appears in a sentence. We can measure it by an equation, \n",
    "\n",
    "- TF = __(Total number of times the word \"W\" occured in the sentence) / (Total number of words in the sentence)__\n",
    "- __Inverse Document Frequency (IDF)__ : How common is a word across all the sentences.\n",
    "- IDF = __log( (Total number of sentences) / (Number of sentences with word \"W\" in it))__\n",
    "* Apply vecorization on the cleaned questions\n",
    "* Here we have used tfidf vectorizer\n",
    "* It’ll see the unique words in the complete para or content given to it and then does one hot encoding accordingly. Also it removes the stopwords and stores the important words which might be used less but gives us more better features. And stores the frequency of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:04.999270Z",
     "start_time": "2019-10-16T16:08:04.995543Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data_Cleanig:\n",
    "    def data_cleanup(self, sentence):\n",
    "        TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "        cleaned_text = re.sub(TEXT_CLEANING_RE, ' ', str(sentence).lower()).strip()\n",
    "        word_tok = nltk.word_tokenize(cleaned_text)\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        lemmatized_words = [lemmatizer.lemmatize(w) for w in word_tok]\n",
    "        return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pass each question to the cleaning funtion defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:07.569911Z",
     "start_time": "2019-10-16T16:08:05.499480Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaning = Data_Cleanig()\n",
    "questions_cleaned = []\n",
    "questions = data['Question'].values\n",
    "for question in questions:\n",
    "    questions_cleaned.append(cleaning.data_cleanup(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:07.575786Z",
     "start_time": "2019-10-16T16:08:07.571897Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Cleaned_questions'] = questions_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:07.713934Z",
     "start_time": "2019-10-16T16:08:07.578419Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('02_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentence __\"How long is the fellowship program?\"__ converted to __\"how long is the fellow program ?\"__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:08.486522Z",
     "start_time": "2019-10-16T16:08:08.466059Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessing():       \n",
    "    # Vectorization for training\n",
    "    def vectorize(self, clean_questions):\n",
    "        vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(min_df=1, stop_words='english')  \n",
    "        vectorizer.fit(clean_questions)\n",
    "        transformed_X_csr = vectorizer.transform(clean_questions)\n",
    "        transformed_X = transformed_X_csr.A # csr_matrix to numpy matrix  \n",
    "        return transformed_X, vectorizer\n",
    "\n",
    "    # Vectorization for input query\n",
    "    def query(self, clean_usr_msg, usr, vectorizer):\n",
    "        t_usr_array= None\n",
    "        try:\n",
    "            t_usr = vectorizer.transform([clean_usr_msg])\n",
    "            t_usr_array = t_usr.toarray()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return \"Could not follow your question [\" + usr + \"], Try again\"\n",
    "\n",
    "        return t_usr_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:10.300942Z",
     "start_time": "2019-10-16T16:08:09.001614Z"
    }
   },
   "outputs": [],
   "source": [
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "preprocessing = Preprocessing()\n",
    "X, vectorizer = preprocessing.vectorize(questions_cleaned)\n",
    "\n",
    "y = data['Class'].values.tolist()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:11.562984Z",
     "start_time": "2019-10-16T16:08:10.307603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 68) (51, 1)\n"
     ]
    }
   ],
   "source": [
    "y = y.reshape(len(y),1)\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:12.531301Z",
     "start_time": "2019-10-16T16:08:11.573879Z"
    }
   },
   "outputs": [],
   "source": [
    "after_vectorize = np.append(X, y, axis=1)\n",
    "np.savetxt(\"03_after_vectorize.csv\", after_vectorize, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Split the data into train and test set\n",
    "- Now our data is ready to feed to the program. But here we'll split the data into train and test dataset so that after training the model we can test the model on the test dataset and find out how accurate are its predictions.\n",
    "- Here we are splitting the data so that the training dataset contains 80% of the data and the test dataset contains 20% of the total data.\n",
    "- Here we are using the train_test_split method from the sklearn library. We'll train our model on x_train and y_train, test it on x_test and y_test.\n",
    "\n",
    "- test_size: Here we specify the size we want for our test dataset.\n",
    "- random_state: When we use a random number generator for number or sequence generation, we give a starting number (AKA seed). When we provide the same seed, every time it’ll generate the same sequence as the first one. That’s why to keep the same random values every time, we give seed as random_state in train_test_split()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:13.396377Z",
     "start_time": "2019-10-16T16:08:12.533255Z"
    }
   },
   "outputs": [],
   "source": [
    "#split the dataset into x and y\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = sklearn.model_selection.train_test_split(\n",
    "        X, y, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't see the values of an entire matrix, but by looking at its shape, we decide if we going in the right direction or not. By using \".shape\" we can see shape of a matrix and it will also helpful in debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:14.324784Z",
     "start_time": "2019-10-16T16:08:13.407042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 68) (13, 68) (38, 1) (13, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_data_train.shape, x_data_test.shape, y_data_train.shape, y_data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train the Model using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:15.601242Z",
     "start_time": "2019-10-16T16:08:15.550837Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepak/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using sklearn linear regression model\n",
    "model = sklearn.svm.SVC(kernel='linear')\n",
    "model.fit(x_data_train, y_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:17.408869Z",
     "start_time": "2019-10-16T16:08:16.545804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (13, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the test data to test the model\n",
    "y_data_pred = model.predict(x_data_test)\n",
    "y_data_pred = y_data_pred.reshape(len(y_data_pred),1)\n",
    "type(y_data_pred), y_data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:17.507718Z",
     "start_time": "2019-10-16T16:08:17.411363Z"
    }
   },
   "outputs": [],
   "source": [
    "#saving the y_pred_test_comparison in the csv file\n",
    "y_pred_test_comparison = np.append(y_data_test, y_data_pred, axis=1)\n",
    "np.savetxt(\"03_y_pred_test_comparison.csv\", y_pred_test_comparison, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:17.605749Z",
     "start_time": "2019-10-16T16:08:17.509715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [-1]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]]\n"
     ]
    }
   ],
   "source": [
    "diffs = y_data_test - y_data_pred\n",
    "print(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T16:08:18.115518Z",
     "start_time": "2019-10-16T16:08:18.111182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "#SVM model score computed by the sklearn library\n",
    "print(\"SVC:\", model.score(x_data_test, y_data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save the model in a pickle file\n",
    "\n",
    "As logistic_model_cv gave us the highest accuracy we'll go with it and save it to pickle file.\n",
    "We save our model to pickle files so that when we want to perform predictions on unseen data, we don't have to train our model again. Any object in python can be pickled so that it can be saved on disk. What pickle does is that it “serializes” the object first before writing it to file. Pickling is a way to convert a python object (list, dict, etc.) into a character stream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-16T17:21:04.789364Z",
     "start_time": "2019-10-16T17:21:04.774833Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../Model Testing/ml-chatbot-backend/model.pkl','wb') as f:\n",
    "        pickle.dump(cleaning, f)\n",
    "        pickle.dump(preprocessing, f)\n",
    "        pickle.dump(vectorizer,f)\n",
    "        pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project has been created to help people understand the complete process of machine learning / data science modeling. These steps ensure that you won't miss out any information in the data set and would also help another person understand your work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
