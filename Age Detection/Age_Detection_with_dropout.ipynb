{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset__ : The dataset consists of images(feature) of indian actors and their age(label) as label. And here we're gonna predict age of an actor from his/her image. For this purpose we're gonna use keras, pandas, numpy and convolutional neural network. Indian Movie Face database (IMFDB) is a large unconstrained face database consisting of 34512 images of 100 Indian actors collected from more than 100 videos. All the images are manually selected and cropped from the video frames resulting in a high degree of variability in terms of scale, pose, expression, illumination, age, resolution, occlusion, and makeup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 1 </b>: Import all the required libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We are going to use following libraries::</b>\n",
    "\n",
    "* __1. Pandas__  --> To import dataset in the form of dataframe\n",
    "* __2. Numpy__ --> To easily handel complex computations\n",
    "* __3. Sklearn__ --> To easily handel machine learning operations\n",
    "* __4. Keras__ --> To easily implement comvolutional neural network\n",
    "* __5. Pickle__ --> To save our model\n",
    "* __6. Seaborn__ --> For ploting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from keras.utils import np_utils\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 2 </b> : Extract all the required data and combine it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to extract iamges and store them into a list 'images'.\n",
    "\n",
    "1. __Train__ : This is the food for our model. It contains the images we’re going to use to teach our model.\n",
    "\n",
    "2. __train.csv__ : This contains the labels for the images in Train dataset, i.e., if the person in the image is young, middle aged or old.\n",
    "\n",
    "3. __Test__ : This file contains the Images we’re going to test our models on after training, to know if our model has learnt to tell the age of a person by looking at an image.\n",
    "\n",
    "4. __test.csv__ : This contains the labels for the images in test dataset, i.e., if the person in the image is young, middle aged or old.\n",
    "\n",
    "Combine the training and testing datasets in the form of an array to teach our model what a young, middle aged and old person looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "path = 'dataset/Train/'\n",
    "flag = os.path.exists('dataset/Train/')\n",
    "if flag:\n",
    "    images = !ls {path}\n",
    "else:\n",
    "    print(\"File does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the CVS file containing name of the images and its labels (age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flag:\n",
    "    train_labels = pd.read_csv('dataset/train.csv')\n",
    "    train_labels.head()\n",
    "else:\n",
    "    print(\"File does not exist!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19906, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that labels are categorised into 3 groups\n",
    "* OLD\n",
    "* MIDDLE \n",
    "* YOUNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MIDDLE', 'YOUNG', 'OLD'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the distrbution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f63bf096cd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(train_labels.Class, data = train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data_combiner will -\n",
    "* __Resize the images__  \n",
    "* __assign proper label to the array form of an image__ \n",
    "\n",
    "return feature and label in the form of array.\n",
    "\n",
    "Size of image affects the computation time. So to reduce the computation time, we'll need to reduce the size of image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_combiner(images, label_data, path):\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    for each in images:\n",
    "        features.append(np.asarray(Image.open(path+each).resize((64,64)), dtype='int32'))\n",
    "        labels.append(np.asarray(label_data[label_data['ID']==each]['Class']))\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using object of class data_Label_Combiner call method Data_combiner\n",
    "train_labels.head()\n",
    "features, labels = data_combiner(images, train_labels, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19906, 64, 64, 3), (19906, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our labels are in categorical form we need to apply one hot encoding on it, so that it'll get converted into numerical form. \n",
    "For this we'll have to convert string data into numerical format by assigning numerical value to each unique element, because sklearn supports one hot encoding only for data in numerical format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['MIDDLE'],\n",
       "       ['MIDDLE'],\n",
       "       ['YOUNG'],\n",
       "       ...,\n",
       "       ['YOUNG'],\n",
       "       ['YOUNG'],\n",
       "       ['OLD']], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = le.transform(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np_utils.to_categorical(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 :  Split the data into train and test set\n",
    "Here we are using train_test_split method from sklearn library. We'll train our model on x_train and y_train, test it on x_test and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features,labels, test_size = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3981, 64, 64, 3), (15925, 64, 64, 3), (3981, 3), (15925, 3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step : Define the structure of neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential model is a linear stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object ( 'clasifier' ) of Sequential model from sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add layers to the neural network using .add method\n",
    "\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(32,3,3, input_shape=(64,64,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Convolution2D(32,3,3, activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(activation='relu', output_dim = 100))\n",
    "classifier.add(Dense(output_dim = 3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a model, you need to configure the learning process, which is done via compile method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(metrics=['accuracy'], loss='binary_crossentropy', optimizer='adam' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator used for augmentation of images according to parameters. Image augmentation is artificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    rescale=1.0/255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "255 is the maximin pixel value. Rescale 1./255 is to transform every pixel value from range [0,255] -> [0,1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_generator will load the data into RAM and perform training on batches that we have provided as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/akanksha/anaconda3/envs/ML/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "3981/3981 [==============================] - 777s 195ms/step - loss: 0.4851 - accuracy: 0.7599 - val_loss: 0.8162 - val_accuracy: 0.8081\n",
      "Epoch 2/20\n",
      "3981/3981 [==============================] - 821s 206ms/step - loss: 0.4139 - accuracy: 0.8087 - val_loss: 0.4743 - val_accuracy: 0.8254\n",
      "Epoch 3/20\n",
      "3981/3981 [==============================] - 844s 212ms/step - loss: 0.3784 - accuracy: 0.8295 - val_loss: 0.3634 - val_accuracy: 0.8292\n",
      "Epoch 4/20\n",
      "3981/3981 [==============================] - 675s 170ms/step - loss: 0.3541 - accuracy: 0.8430 - val_loss: 0.5254 - val_accuracy: 0.8258\n",
      "Epoch 5/20\n",
      "3981/3981 [==============================] - 642s 161ms/step - loss: 0.3351 - accuracy: 0.8528 - val_loss: 0.4645 - val_accuracy: 0.8341\n",
      "Epoch 6/20\n",
      "3981/3981 [==============================] - 641s 161ms/step - loss: 0.3172 - accuracy: 0.8615 - val_loss: 0.3198 - val_accuracy: 0.8315\n",
      "Epoch 7/20\n",
      "3981/3981 [==============================] - 642s 161ms/step - loss: 0.3027 - accuracy: 0.8683 - val_loss: 0.3860 - val_accuracy: 0.8320\n",
      "Epoch 8/20\n",
      "3981/3981 [==============================] - 642s 161ms/step - loss: 0.2920 - accuracy: 0.8737 - val_loss: 0.3236 - val_accuracy: 0.8346\n",
      "Epoch 9/20\n",
      "3981/3981 [==============================] - 643s 161ms/step - loss: 0.2838 - accuracy: 0.8781 - val_loss: 0.5307 - val_accuracy: 0.8318\n",
      "Epoch 10/20\n",
      "3981/3981 [==============================] - 641s 161ms/step - loss: 0.2757 - accuracy: 0.8820 - val_loss: 0.1937 - val_accuracy: 0.8325\n",
      "Epoch 11/20\n",
      "3981/3981 [==============================] - 642s 161ms/step - loss: 0.2688 - accuracy: 0.8853 - val_loss: 0.6357 - val_accuracy: 0.8390\n",
      "Epoch 12/20\n",
      "3981/3981 [==============================] - 661s 166ms/step - loss: 0.2602 - accuracy: 0.8897 - val_loss: 0.4148 - val_accuracy: 0.8261\n",
      "Epoch 13/20\n",
      "3981/3981 [==============================] - 758s 190ms/step - loss: 0.2563 - accuracy: 0.8909 - val_loss: 0.4081 - val_accuracy: 0.8364\n",
      "Epoch 14/20\n",
      "3981/3981 [==============================] - 725s 182ms/step - loss: 0.2492 - accuracy: 0.8949 - val_loss: 0.3525 - val_accuracy: 0.8363\n",
      "Epoch 15/20\n",
      "3981/3981 [==============================] - 637s 160ms/step - loss: 0.2456 - accuracy: 0.8965 - val_loss: 0.4613 - val_accuracy: 0.8274\n",
      "Epoch 16/20\n",
      "3981/3981 [==============================] - 2308s 580ms/step - loss: 0.2411 - accuracy: 0.8984 - val_loss: 0.4292 - val_accuracy: 0.8433\n",
      "Epoch 17/20\n",
      "3981/3981 [==============================] - 643s 161ms/step - loss: 0.2383 - accuracy: 0.8998 - val_loss: 0.3331 - val_accuracy: 0.8379\n",
      "Epoch 18/20\n",
      "3981/3981 [==============================] - 647s 163ms/step - loss: 0.2307 - accuracy: 0.9041 - val_loss: 0.6214 - val_accuracy: 0.8292\n",
      "Epoch 19/20\n",
      "3981/3981 [==============================] - 652s 164ms/step - loss: 0.2296 - accuracy: 0.9040 - val_loss: 0.6606 - val_accuracy: 0.8421\n",
      "Epoch 20/20\n",
      "3981/3981 [==============================] - 832s 209ms/step - loss: 0.2267 - accuracy: 0.9055 - val_loss: 0.3000 - val_accuracy: 0.8398\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit_generator(train_generator.flow(x_train,y_train,batch_size=32)\n",
    "                        , steps_per_epoch=len(x_train)\n",
    "                        , epochs=20\n",
    "                        ,validation_data=val_generator.flow(x_test,y_test,batch_size=32)\n",
    "                        ,validation_steps=len(x_test), workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15925/15925 [==============================] - 10s 641us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.967668877007261, 0.6735949516296387]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x_test ,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the values for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model in pickle file\n",
    "\n",
    "As logistic_model_cv gave us highest accuracy we'll go with it and save it to pickle file.\n",
    "We save our model to pickle file so that when we want to perform predictions on unseen data, we don't have to train our model again. Any object in python can be pickled so that it can be saved on disk. What pickle does is that it “serialises” the object first before writing it to file. Pickling is a way to convert a python object (list, dict, etc.) into a character stream.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "with open('model/age_de_model.pkl','wb') as f:\n",
    "    pickle.dump(le,f)\n",
    "    pickle.dump(classifier,f)\n",
    "    \n",
    "classifier.save_weights(\"model/age_de_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
