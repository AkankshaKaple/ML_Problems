{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset__ : The dataset consists of images(feature) of indian actors and their age(label) as label. And here we're gonna predict age of an actor from his/her image. For this purpose we're gonna use keras, pandas, numpy and convolutional neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 1 </b>: Import all the required libraries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We are going to use following libraries::</b>\n",
    "\n",
    "* __1. Pandas__  --> To import dataset in the form of dataframe\n",
    "* __2. Numpy__ --> To easily handel complex computations\n",
    "* __3. Sklearn__ --> To easily handel machine learning operations\n",
    "* __4. Keras__ --> To easily implement comvolutional neural network\n",
    "* __5. Pickle__ --> To save our model\n",
    "* __6. Seaborn__ --> For ploting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from keras.utils import np_utils\n",
    "import seaborn as sb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Step 2 </b> : Extract all the required data and combine it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path to extract iamges and store them into a list 'images'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/train/Train/'\n",
    "images = !ls {path}\n",
    "# images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the CVS file containing name of the images and its labels (age)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17814.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21283.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16496.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4487.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   Class\n",
       "0    377.jpg  MIDDLE\n",
       "1  17814.jpg   YOUNG\n",
       "2  21283.jpg  MIDDLE\n",
       "3  16496.jpg   YOUNG\n",
       "4   4487.jpg  MIDDLE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('dataset/train/train.csv')\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19906, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that labels are categorised into 3 groups\n",
    "* OLD\n",
    "* MIDDLE \n",
    "* YOUNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MIDDLE', 'YOUNG', 'OLD']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = list((train_labels['Class']).unique())\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the distrbution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd745aa4048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(train_labels.Class, data = train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data_combiner will -\n",
    "* __Resize the images__  \n",
    "* __assign proper label to the array form of an image__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and return feature and label in the form of array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_Label_Combiner:\n",
    "\n",
    "    def Data_combiner(self,images, labels, path):\n",
    "        x_train=[]\n",
    "        y_train=[]\n",
    "        for each in images:\n",
    "            x_train.append(np.asarray(Image.open(path+each).resize((64,64)), dtype='int32'))\n",
    "            y_train.append(np.asarray(labels[labels['ID']==each]['Class']))\n",
    "        return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object of data_Label_Combiner class as 'dlc'\n",
    "dlc = data_Label_Combiner() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using object of class data_Label_Combiner call method Data_combiner\n",
    "x_train, y_train = dlc.Data_combiner(images, train_labels, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our labels are in categorical form we need to apply one hot encoding on it, so that it'll get converted into numerical form. \n",
    "For this we'll have to convert string data into numerical format by assigning numerical value to each unique element, because sklearn supports one hot encoding only for data in numerical format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['MIDDLE'],\n",
       "       ['MIDDLE'],\n",
       "       ['YOUNG'],\n",
       "       ...,\n",
       "       ['YOUNG'],\n",
       "       ['YOUNG'],\n",
       "       ['OLD']], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, ..., 2, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = le.transform(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 :  Split the data into train and test set\n",
    "Here we are using train_test_split method from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train,y_train, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17915, 64, 64, 3), (1991, 64, 64, 3), (17915, 3), (1991, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step : Define the structure of neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sequential model is a linear stack of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object ( 'clasifier' ) of Sequential model from sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add layers to the neural network using .add method\n",
    "\n",
    "The model needs to know what input shape it should expect. For this reason, the first layer in a Sequential model (and only the first, because following layers can do automatic shape inference) needs to receive information about its input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/admin28/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Convolution2D(32,3,3, input_shape=(64,64,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Convolution2D(32,3,3, activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(activation='relu', output_dim = 100))\n",
    "classifier.add(Dense(output_dim = 3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a model, you need to configure the learning process, which is done via the compile method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(metrics=['accuracy'], loss='binary_crossentropy', optimizer='adam' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator used for augmentation of images according to parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    rescale=1.0/255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "255 is the maximin pixel value. Rescale 1./255 is to transform every pixel value from range [0,255] -> [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_generator will load the data into RAM and perform training on batches using epochs that we have provided as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/admin28/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "17915/17915 [==============================] - 2220s 124ms/step - loss: 0.4303 - acc: 0.7984 - val_loss: 0.3556 - val_acc: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd745583780>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(train_generator.flow(x_train,y_train,batch_size=32)\n",
    "                        , steps_per_epoch=len(x_train)\n",
    "                        , epochs=1\n",
    "                        ,validation_data=val_generator.flow(x_test,y_test,batch_size=32)\n",
    "                        ,validation_steps=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991/1991 [==============================] - 2s 769us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.485825699576776, 0.7130420310062598]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.evaluate(x_test ,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the values for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(classifier,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
